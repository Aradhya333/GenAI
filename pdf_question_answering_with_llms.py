# -*- coding: utf-8 -*-
"""PDF Question Answering with LLMs.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H_1r2JsOVD8jQqOImznFcW8pxUwh-HiB

This project demonstrates how to build a Question Answering system that allows users to upload multiple PDF documents (research papers, study materials, reports, etc.), ask natural language questions, and get answers by leveraging transformer-based models.

The pipeline includes:
- Extracting text from PDFs using PyMuPDF (fitz)
- Embedding chunks with SentenceTransformers
- Finding the most relevant text chunk for a query
- Running Question-Answering with Hugging Faceâ€™s deepset/roberta-base-squad2
"""

# Install Required Libraries
!pip install pymupdf transformers sentence-transformers torch

import fitz
import torch
import os
from transformers import pipeline
from sentence_transformers import SentenceTransformer, util
from google.colab import files

# Hugging Face QA Model
qa_model = pipeline("question-answering", model="deepset/roberta-base-squad2")

# SentenceTransformer Model for embeddings
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# Extract Text from PDF
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text_chunks = [page.get_text("text") for page in doc]
    return text_chunks

# Find Most Relevant Text Chunk
def get_most_relevant_text_chunks(query, text_chunks):

    # Convert query into embeddings
    question_embedding = embedding_model.encode(query, convert_to_tensor=True)

    # Convert chunks into embeddings
    chunk_embeddings = [embedding_model.encode(chunk, convert_to_tensor=True) for chunk in text_chunks]

    # Calculate cosine similarity for each chunk
    similarities = [util.pytorch_cos_sim(question_embedding, chunk_emb)[0].item() for chunk_emb in chunk_embeddings]

    # Get index of best matching chunk
    best_chunk_idx = similarities.index(max(similarities))
    return text_chunks[best_chunk_idx]

# Function - QA on a PDF
def q_a(query, pdf_path):
    text_chunks = extract_text_from_pdf(pdf_path)
    relevant_chunk = get_most_relevant_text_chunks(query, text_chunks)
    answer = qa_model(question= query, context= relevant_chunk)
    return answer

# Upload Multiple PDFs at Once
def upload_multiple_pdfs():
    print(" Please select and upload all your PDF files (you can select multiple).")
    uploaded = files.upload()   # Allows selecting multiple files at once
    uploaded_files = {}

    for name, data in uploaded.items():
        with open(name, 'wb') as f:
            f.write(data)
        uploaded_files[name] = os.path.abspath(name)  # Store absolute path
        print(f"Uploaded: {name}")

    return uploaded_files

uploaded_pdf_paths = upload_multiple_pdfs()

print("\n All uploaded PDFs:")
for title, path in uploaded_pdf_paths.items():
    print(f"- {title}: {path}")

# Ask Questions in a Loop
while True:
    user_input = input("\n Ask a question (or type 'q' to quit): ")
    if user_input.lower() == 'q':
        print(" Exiting QA System. Goodbye!")
        break

    # Let user choose which PDF to query
    print("\nAvailable PDFs:")
    for i, title in enumerate(uploaded_pdf_paths.keys(), 1):
        print(f"{i}. {title}")
    choice = int(input("Choose a PDF by number: "))
    selected_pdf_path = list(uploaded_pdf_paths.values())[choice - 1]

    # Get Answer
    result = q_a(user_input, selected_pdf_path)
    print(" Answer:", result['answer'])

